{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Layered RS Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для src, utils, metrics вы можете скачать из [этого](https://github.com/geangohn/recsys-tutorial) github репозитория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "### TODO REMOVE CONSTRAINTS:\n",
    "#############################\n",
    "\n",
    "\"\"\"\n",
    "- Для каждого юзера 5 рекомендаций (иногда модели могут возвращать < 5)\n",
    "- 2 новых товара (юзер никогда не покупал)\n",
    "- 1 дорогой товар, > 7 долларов\n",
    "- Все товары из разных категорий (категория - sub_commodity_desc)\n",
    "\n",
    "- Стоимость каждого рекомендованного товара > 1 доллара\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "import re\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "import os, sys\n",
    "\n",
    "from src.metrics import precision_at_k\n",
    "from implicit.nearest_neighbours import ItemItemRecommender, bm25_weight \n",
    "# from src.utils import prefilter_items\n",
    "# from src.recommenders import MainRecommender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Settings && Constants \n",
    "###############################\n",
    "\n",
    "DATA_PATH = './data/retail_train.csv'\n",
    "TEST_PATH = './data/retail_test1.csv'\n",
    "ITEM_FEATURES_PATH = './data/product.csv'\n",
    "USER_FEATURES_PATH = './data/hh_demographic.csv'\n",
    "\n",
    "TEST_SIZE_WEEKS = (3,3)\n",
    "N_POPULAR_ITEMS = 4000\n",
    "INIT_NUM_RECS = 500\n",
    "N_FIN_RECS = 5\n",
    "# NUM_THREADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# MODULES \n",
    "###############################\n",
    "\n",
    "value_string_template = '\\033[91m[[value]]\\033[0m'\n",
    "\n",
    "def prefilter_items(data, take_n_popular=5000, margin_slice_rate=0.9):\n",
    "    \n",
    "    \"\"\"Предфильтрация товаров\"\"\"\n",
    "    \n",
    "    n_before = value_string_template.replace('[[value]]', str(data['item_id'].nunique()))\n",
    "    \n",
    "    \n",
    "    # drop 0 purchases\n",
    "    data = data.drop(data[data['quantity']==0].index)\n",
    "    \n",
    "    # Calculate price\n",
    "    data['price'] = data['sales_value'] / data['quantity']\n",
    "    \n",
    "    # 1. Drop prices < 1$\n",
    "    data = data[data['price'] > 1]\n",
    "    \n",
    "    # Удаление товаров со средней ценой > 15$\n",
    "    data = data[data['price'] < 15]\n",
    "    \n",
    "    # Уберем товары, которые не продавались за последние 5 месяцев\n",
    "    purchases_last_week = data.groupby('item_id')['week_no'].max().reset_index()\n",
    "    weeks = purchases_last_week[\n",
    "        purchases_last_week['week_no'] > data['week_no'].max() - 5].item_id.tolist()\n",
    "    data = data[data['item_id'].isin(weeks)]\n",
    "    \n",
    "    # Удаление 10% товаров c наименьшей выручкой (сдвигает минимум выручки с 1.1$ до 94.8$ для unsplitted data)\n",
    "    marginality = data.groupby('item_id')['sales_value'].sum().reset_index()\n",
    "    ten_percent_slice_idx = int(marginality.shape[0] * margin_slice_rate)\n",
    "\n",
    "    top_margin = marginality.sort_values('sales_value', ascending=False)[:ten_percent_slice_idx].item_id.tolist()\n",
    "    data = data[data['item_id'].isin(top_margin)]\n",
    "    \n",
    "    # Выбор топ-N самых популярных товаров (N = take_n_popular)\n",
    "    popularity = data.groupby('item_id')['quantity'].sum().reset_index()\n",
    "    top_popular = popularity.sort_values('quantity', ascending=False)[:take_n_popular].item_id.tolist()\n",
    "    data = data[data['item_id'].isin(top_popular)]\n",
    "    \n",
    "    n_after = value_string_template.replace('[[value]]', str(data['item_id'].nunique()))\n",
    "    print(f\"Items variety reduced from: {n_before} to: {n_after} samples...\", end='')\n",
    "    print('\\033[94mDone\\033[0m')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_raw_data_splits(data_path, n_weeks_split=(3, 3), mode=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return data splits depending on mode:\n",
    "    \n",
    "    MODE 0: No split\n",
    "    MODE 1: One level split\n",
    "    MODE 2: Two level split\n",
    "    \n",
    "    data_train: base train split\n",
    "    data_test: used for lvl 1 validation & lvl 2 train\n",
    "    data_val: used for lvl 2 validation\n",
    "    \n",
    "    for lvl_size_weeks in [6, 3] returns:   \n",
    "    train_lvl1: week_no (1-85), val_lvl1 & train_lvl2: week_no (86-91), val_lvl2: week_no (92-95)\n",
    "    \"\"\"\n",
    "    print(\"Preparing raw data...\", end='')\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    if mode == 0:\n",
    "        return data\n",
    "    \n",
    "    if mode == 1:\n",
    "        print(\"Selected one level mode...\", end='')\n",
    "        data_train = data[data['week_no'] < data['week_no'].max() - (n_weeks_split[0] + n_weeks_split[1])]\n",
    "        data_test = data[(data['week_no'] >= data['week_no'].max() - (n_weeks_split[0] + n_weeks_split[1]))]\n",
    "        print('\\033[94mDone\\033[0m') \n",
    "        \n",
    "        return data, data_train, data_test\n",
    "    \n",
    "    elif mode == 2:\n",
    "        print(\"Selected two level mode...\", end='')\n",
    "        data_train = data[data['week_no'] < data['week_no'].max() - (n_weeks_split[0] + n_weeks_split[1])]\n",
    "        data_test = data[(data['week_no'] >= data['week_no'].max() /\n",
    "                               - (n_weeks_split[0] + n_weeks_split[1])) &\n",
    "                              (data['week_no'] < data['week_no'].max() - (n_weeks_split[1]))]\n",
    "        data_val_1 = data_test.copy()\n",
    "        data_val_2 = data[data['week_no'] >= data['week_no'].max() - n_weeks_split[1]] \n",
    "        print('\\033[94mDone\\033[0m') \n",
    "\n",
    "        return data, data_train, data_test, data_val_1, data_val_2\n",
    "    else:\n",
    "        print('\\033[91mError. Mode not understood\\033[0m')\n",
    "        return None\n",
    "\n",
    "    \n",
    "def get_price_list(data_1, data_2, _id='item_id', target='price'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Used 4 creating check dict (price list)\n",
    "    From all historical data\n",
    "    Can be used once and stored then updated if needs\n",
    "    \"\"\"\n",
    "    \n",
    "    pl_1 = data_1.groupby(_id)[target].mean().reset_index()\n",
    "    pl_2 = data_2.groupby(_id)[target].mean().reset_index()\n",
    "    d1 = dict(zip(pl_1[_id], pl_1[target]))\n",
    "    d2 = dict(zip(pl_2[_id], pl_2[target]))\n",
    "    pl_emb = {**d1, **d2}\n",
    "    \n",
    "    return pl_emb\n",
    "\n",
    "\n",
    "def get_bought_ever_list(data_1, data_2, _id='user_id', target='item_id'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Used 4 creating check dict (user's ever bought list)\n",
    "    From all historical data\n",
    "    Can be used once and stored then updated if needs\n",
    "    \"\"\"\n",
    "    \n",
    "    pl_1 = data_1.groupby(_id)[target].unique().reset_index()\n",
    "    pl_2 = data_2.groupby(_id)[target].unique().reset_index()\n",
    "    d1 = dict(zip(pl_1[_id], pl_1[target]))\n",
    "    d2 = dict(zip(pl_2[_id], pl_2[target]))\n",
    "    pl_emb = {**d1, **d2}\n",
    "    \n",
    "    return pl_emb\n",
    "\n",
    "\n",
    "def get_item_commodities_list(feats, _id='item_id', target='sub_commodity_desc_code'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Used 4 creating check dict (item_id - commodity_type)\n",
    "    From all historical data\n",
    "    Can be used once and stored then updated if needs\n",
    "    \"\"\"\n",
    "    \n",
    "    res = dict(zip(feats[_id], feats[target]))\n",
    "    return res\n",
    "        \n",
    "    \n",
    "def preprare_features(item_features_path, user_features_path):\n",
    "    \n",
    "    \"\"\"Loads raw item and user features:\"\"\"\n",
    "    \n",
    "    print(\"Preparing raw features...\", end='')\n",
    "    item_features = pd.read_csv(item_features_path)\n",
    "    user_features = pd.read_csv(user_features_path)\n",
    "\n",
    "    # column processing\n",
    "    item_features.columns = [col.lower() for col in item_features.columns]\n",
    "    user_features.columns = [col.lower() for col in user_features.columns]\n",
    "    item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "    user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "    \n",
    "    # encode commodities in item_features\n",
    "    item_features['sub_commodity_desc'] = pd.Categorical(item_features['sub_commodity_desc'])\n",
    "    item_features['sub_commodity_desc_code'] = item_features['sub_commodity_desc'].cat.codes\n",
    "    \n",
    "    print('\\033[94mDone\\033[0m')\n",
    "    \n",
    "    return item_features, user_features\n",
    "\n",
    "\n",
    "\n",
    "class MainRecommender:\n",
    "    \"\"\"Рекоммендации, которые можно получить из ALS\n",
    "    Input\n",
    "    -----\n",
    "    user_item_matrix: pd.DataFrame\n",
    "        Матрица взаимодействий user-item\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, prices, weighting=True):\n",
    "\n",
    "        # Топ покупок каждого юзера\n",
    "        self.top_purchases = data.groupby(['user_id', 'item_id'])['sales_value'].count().reset_index()\n",
    "        self.top_purchases.sort_values('sales_value', ascending=False, inplace=True)\n",
    "\n",
    "        # Топ покупок по всему датасету\n",
    "        self.overall_top_purchases = data.groupby('item_id')['sales_value'].count().reset_index()\n",
    "        self.overall_top_purchases.sort_values('sales_value', ascending=False, inplace=True)\n",
    "        self.overall_top_purchases = self.overall_top_purchases.item_id.tolist()\n",
    "\n",
    "        self.user_item_matrix, self.matrix_index, self.matrix_columns = self._prepare_matrix(data)  # pd.DataFrame\n",
    "        self.id_to_itemid, self.id_to_userid, \\\n",
    "            self.itemid_to_id, self.userid_to_id = self._prepare_dicts(self.user_item_matrix)\n",
    "\n",
    "        if weighting:\n",
    "            self.user_item_matrix = bm25_weight(self.user_item_matrix.T).T\n",
    "\n",
    "        self.model = self.fit(self.user_item_matrix)\n",
    "        # self.bpr = self.fit_bpr(self.user_item_matrix)\n",
    "        self.own_recommender = self.fit_own_recommender(self.user_item_matrix)\n",
    "        \n",
    "        self.item_factors = self.model.item_factors\n",
    "        self.user_factors = self.model.user_factors\n",
    "#         self.price_list = prices\n",
    "        \n",
    "        self.items_emb_df, self.users_emb_df = self.get_embeddings(self)\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def get_embeddings(self):\n",
    "        items_emb = self.item_factors\n",
    "        items_emb_df = pd.DataFrame(items_emb)\n",
    "        items_emb_df.reset_index(inplace=True)\n",
    "        items_emb_df['item_id'] = items_emb_df['index'].apply(lambda x: self.id_to_itemid[x])\n",
    "        items_emb_df = items_emb_df.drop('index', axis=1)\n",
    "\n",
    "        users_emb = self.user_factors\n",
    "        users_emb_df = pd.DataFrame(users_emb)\n",
    "        users_emb_df.reset_index(inplace=True)\n",
    "        users_emb_df['user_id'] = users_emb_df['index'].apply(lambda x: self.id_to_userid[x])\n",
    "        users_emb_df = users_emb_df.drop('index', axis=1)\n",
    "\n",
    "        return items_emb_df, users_emb_df\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_matrix(data):\n",
    "        \"\"\"Готовит user-item матрицу\"\"\"\n",
    "        user_item_matrix = pd.pivot_table(data,\n",
    "                                          index='user_id', \n",
    "                                          columns='item_id',\n",
    "                                          values='quantity',\n",
    "                                          aggfunc='count',\n",
    "                                          fill_value=0\n",
    "                                          )\n",
    "        matrix_index = user_item_matrix.index\n",
    "        matrix_columns = user_item_matrix.columns\n",
    "\n",
    "        user_item_matrix = user_item_matrix.astype(float)  # необходимый тип матрицы для implicit\n",
    "        return user_item_matrix, matrix_index, matrix_columns\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_dicts(user_item_matrix):\n",
    "        \"\"\"Подготавливает вспомогательные словари\"\"\"\n",
    "\n",
    "        userids = user_item_matrix.index.values\n",
    "        itemids = user_item_matrix.columns.values\n",
    "\n",
    "        matrix_userids = np.arange(len(userids))\n",
    "        matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "        id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "        id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "        itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "        userid_to_id = dict(zip(userids, matrix_userids))\n",
    "\n",
    "        return id_to_itemid, id_to_userid, itemid_to_id, userid_to_id\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def fit_own_recommender(user_item_matrix):\n",
    "        \n",
    "        \"\"\"Обучает модель, которая рекомендует товары, среди товаров, купленных юзером\"\"\"\n",
    "        \n",
    "        own_recommender = ItemItemRecommender(K=1)\n",
    "        own_recommender.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "        return own_recommender\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def fit(user_item_matrix, n_factors=32, regularization=0.001, iterations=20, num_threads=8):\n",
    "        \n",
    "        \"\"\"Обучает ALS\"\"\"\n",
    "        \n",
    "        model = AlternatingLeastSquares(factors=n_factors,\n",
    "                                        regularization=regularization,\n",
    "                                        iterations=iterations,\n",
    "                                        num_threads=num_threads)\n",
    "        model.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def fit_bpr(user_item_matrix, n_factors=31, regularization=0.001, iterations=20, num_threads=8):\n",
    "        model = BayesianPersonalizedRanking(factors=n_factors,\n",
    "                                             regularization=regularization,\n",
    "                                             iterations=iterations,\n",
    "                                             num_threads=num_threads)\n",
    "        model.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "        return model\n",
    "\n",
    "    def _update_dict(self, user_id):\n",
    "        \n",
    "        \"\"\"Если появился новый user / item, то нужно обновить словари\"\"\"\n",
    "        \n",
    "        if user_id not in self.userid_to_id.keys():\n",
    "            print(f\"user_id: '\\033[94m{user_id}\\033[0m' not in dict, add...\")\n",
    "            max_id = max(list(self.userid_to_id.values()))\n",
    "            max_id += 1\n",
    "            self.userid_to_id.update({user_id: max_id})\n",
    "            self.id_to_userid.update({max_id: user_id})\n",
    "            \n",
    "\n",
    "    def _get_similar_item(self, item_id):\n",
    "        \n",
    "        \"\"\"Находит товар, похожий на item_id\"\"\"\n",
    "        \n",
    "        # Товар похож на себя -> рекомендуем 2 товара\n",
    "        recs = self.model.similar_items(self.itemid_to_id[item_id], N=2)\n",
    "        top_rec = recs[1][0]  # И берем второй (не товар из аргумента метода)\n",
    "        return self.id_to_itemid[top_rec]\n",
    "    \n",
    "\n",
    "    def _extend_with_top_popular(self, recommendations, N=5):\n",
    "        \n",
    "        \"\"\"Если кол-во рекоммендаций < N, то дополняем их топ-популярными\"\"\"\n",
    "        \n",
    "        if len(recommendations) < N:\n",
    "            recommendations.extend(self.overall_top_purchases[:N])\n",
    "            recommendations = recommendations[:N]\n",
    "        return recommendations\n",
    "    \n",
    "\n",
    "    def _get_recommendations(self, user, model, N=5):\n",
    "        \n",
    "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
    "        \n",
    "        \n",
    "        if user not in self.userid_to_id.keys():\n",
    "            self._update_dict(user_id=user)\n",
    "            res = []\n",
    "            res = self._extend_with_top_popular(res, N=N)\n",
    "        else:\n",
    "        \n",
    "        \n",
    "            res = [self.id_to_itemid[rec[0]] for rec in model.recommend(userid=self.userid_to_id[user],\n",
    "                                            user_items=csr_matrix(self.user_item_matrix).tocsr(),\n",
    "                                            N=N,\n",
    "                                            filter_already_liked_items=False,\n",
    "                                            filter_items=None,\n",
    "                                            recalculate_user=True)]\n",
    "            res = self._extend_with_top_popular(res, N=N)\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "    \n",
    "\n",
    "    def get_als_recommendations(self, user, N=5):\n",
    "        \n",
    "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
    "        \n",
    "#         self._update_dict(user_id=user)\n",
    "        return self._get_recommendations(user, model=self.model, N=N)\n",
    "    \n",
    "    def get_bayesian_recommendations(self, user, N=5):\n",
    "        return self._get_recommendations(user, model=self.bpr, N=N)\n",
    "\n",
    "    def get_own_recommendations(self, user, N=5):\n",
    "        \n",
    "        \"\"\"Рекомендуем товары среди тех, которые юзер уже купил\"\"\"\n",
    "        \n",
    "#         self._update_dict(user_id=user)\n",
    "        return self._get_recommendations(user, model=self.own_recommender, N=N)\n",
    "    \n",
    "\n",
    "    def get_similar_items_recommendation(self, user, N=5):\n",
    "        \n",
    "        \"\"\"Рекомендуем товары, похожие на топ-N купленных юзером товаров\"\"\"\n",
    "        \n",
    "        top_users_purchases = self.top_purchases[self.top_purchases['user_id'] == user].head(N)\n",
    "\n",
    "        res = top_users_purchases['item_id'].apply(lambda x: self._get_similar_item(x)).tolist()\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "    \n",
    "\n",
    "    def get_similar_users_recommendation(self, user, N=5):\n",
    "        \n",
    "        \"\"\"Рекомендуем топ-N товаров, среди купленных похожими юзерами\"\"\"\n",
    "        \n",
    "        res = []\n",
    "\n",
    "        # Находим топ-N похожих пользователей\n",
    "        similar_users = self.model.similar_users(self.userid_to_id[user], N=N+1)\n",
    "        similar_users = [rec[0] for rec in similar_users]\n",
    "        similar_users = similar_users[1:]   # удалим юзера из запроса\n",
    "\n",
    "        for user in similar_users:\n",
    "            res.extend(self.get_own_recommendations(user, N=1))\n",
    "\n",
    "\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "    \n",
    "    \n",
    "def check_valid_items(res,\n",
    "                      user,\n",
    "                      item_to_commodity,\n",
    "                      itemid_to_price,\n",
    "                      user_bought_history,\n",
    "                      n=5,\n",
    "                      max_price_constraint=7,\n",
    "                      max_n_new_items_constraint=2\n",
    "                     ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Constraints Checker Module.\n",
    "    Check commended items for user.\n",
    "    Input: res:array with len=n\n",
    "    Return: error flag, one-hot encodded errors\n",
    "    \"\"\"\n",
    "    \n",
    "    # res: list result of n=5 elements\n",
    "    \n",
    "    err_flag = 0  # error flag\n",
    "    err_pos = np.zeros(len(res))  # penalty weights for items to change positions\n",
    "    user_history = user_bought_history[user][:10]  # user purchases of unique items history\n",
    "    price_checklist = np.zeros(len(res))  # price list for checking conditions\n",
    "    unique_checklist = np.zeros(len(res))  # unique item positions counter\n",
    "    \n",
    "    c = []\n",
    "    for i, item in enumerate(res):\n",
    "        commodity = item_to_commodity[item]\n",
    "        price_checklist[i] = itemid_to_price[item]        \n",
    "        \n",
    "        # check if code already exists in recs. If true change first duplicate\n",
    "        if commodity in c:\n",
    "            err_flag = 1\n",
    "            err_pos[i] += 1  # add penalty for mismatch element position\n",
    "            \n",
    "        # keep track of unique items\n",
    "        if item not in user_history:\n",
    "            unique_checklist[i] = 1\n",
    "        c.append(commodity)\n",
    "        \n",
    "    max_price = price_checklist[np.argmax(price_checklist)]\n",
    "    \n",
    "    # if no expensive items in list, mark last element\n",
    "    if max_price < max_price_constraint:\n",
    "        err_flag = 1\n",
    "        \n",
    "        # add penalty to last highest element\n",
    "        #  len(res-1) - np.argmax(err_pos[::-1]) keeps track on the last element if equal weights exist like 0\n",
    "        #  used in case of ranked elements\n",
    "        err_pos[len(res)-1 - np.argmax(err_pos[::-1])] += 1\n",
    "    \n",
    "    # if not enough unique elements, mark last element\n",
    "    if unique_checklist.sum() < max_n_new_items_constraint:\n",
    "        err_flag = 1\n",
    "        # add penalty to last highest element\n",
    "        err_pos[len(res)-1 - np.argmax(err_pos[::-1])] += 1\n",
    "    \n",
    "    return err_flag, err_pos\n",
    "\n",
    "            \n",
    "\n",
    "def postfilter_items(data,\n",
    "                     pop_recs,\n",
    "                     item_to_commodity,\n",
    "                     itemid_to_price,\n",
    "                     user_bought_history,\n",
    "                     n=5,\n",
    "                     target_col='recomendations',\n",
    "                     res_col='result'\n",
    "                    ):    \n",
    "    \n",
    "    \"\"\"\n",
    "    Input: user recommendations: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # make result placeholders\n",
    "    data[res_col] = np.nan\n",
    "    data[res_col] = data[res_col].astype('object')\n",
    "    \n",
    "    \n",
    "    for index, row in data.iterrows():       \n",
    "        if row.user_id %500==0:\n",
    "            print(f\"iter on {row.user_id}\")\n",
    "        \n",
    "        recs = row[target_col]\n",
    "        result = recs[:n] # list with n item_id recs\n",
    "        flag, err_positions = check_valid_items(result,\n",
    "                                                row.user_id,\n",
    "                                                item_to_commodity,\n",
    "                                                itemid_to_price,\n",
    "                                                user_bought_history,\n",
    "                                                n)\n",
    "\n",
    "        take_from_pos = n + 1  # set initial position of new element to substitute as next # after existing recs\n",
    "        ov=1\n",
    "        while flag:\n",
    "            \n",
    "            pos_list = np.where(err_positions>0)[0]  # invalid element positions pointer\n",
    "            # change each invalid element \n",
    "            for pos in pos_list:\n",
    "                if take_from_pos%INIT_NUM_RECS==0 and not ov:  # INIT_NUM_RECS\n",
    "#                     print(take_from_pos)\n",
    "                    take_from_pos = 1\n",
    "                    ov=1\n",
    "                    \n",
    "                if ov:\n",
    "                    result[pos] = pop_recs[take_from_pos]\n",
    "                    take_from_pos +=1\n",
    "                    \n",
    "                else:\n",
    "                    result[pos] = recs[take_from_pos]\n",
    "                    take_from_pos +=1\n",
    "                \n",
    "            # check new recommendations\n",
    "            flag, err_positions = check_valid_items(result,\n",
    "                                                row.user_id,\n",
    "                                                item_to_commodity,\n",
    "                                                itemid_to_price,\n",
    "                                                user_bought_history,\n",
    "                                                n)        \n",
    "                    \n",
    "        data.at[index, res_col] = result\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def money_precision_at_k(recommended_list, bought_list, prices, k=5):\n",
    "    \n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list[:k])\n",
    "    \n",
    "    prices_recommended = np.array([prices[i] for i in recommended_list])\n",
    "    prices_bought = np.array([prices[i] for i in bought_list])\n",
    "    \n",
    "    flags = np.isin(bought_list, recommended_list)\n",
    "    precision = np.dot(flags, prices_bought) / np.dot(np.ones(k), prices_recommended)\n",
    "    \n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing raw data...Selected one level mode...\u001b[94mDone\u001b[0m\n",
      "Preparing raw data...Preparing raw features...\u001b[94mDone\u001b[0m\n",
      "Wall time: 5.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# weeks split: 1-88, 89-95, 96-98\n",
    "data, data_train_lvl_1, data_val_lvl_1 = get_raw_data_splits(DATA_PATH, mode=1)\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()\n",
    "data_val_lvl_2 = get_raw_data_splits(TEST_PATH, mode=0)\n",
    "# TWO LVL PREPARATION\n",
    "\n",
    "# data, data_train_lvl_1, data_val_lvl_1, data_train_lvl_2, data_val_lvl_2 = get_raw_data_splits(\n",
    "#     DATA_PATH, TEST_SIZE_WEEKS, mode=1)\n",
    "\n",
    "item_features, user_features = preprare_features(ITEM_FEATURES_PATH, USER_FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items variety reduced from: \u001b[91m85334\u001b[0m to: \u001b[91m4000\u001b[0m samples...\u001b[94mDone\u001b[0m\n",
      "Items variety reduced from: \u001b[91m30040\u001b[0m to: \u001b[91m4000\u001b[0m samples...\u001b[94mDone\u001b[0m\n",
      "Items variety reduced from: \u001b[91m4000\u001b[0m to: \u001b[91m3600\u001b[0m samples...\u001b[94mDone\u001b[0m\n",
      "Items variety reduced from: \u001b[91m4000\u001b[0m to: \u001b[91m3600\u001b[0m samples...\u001b[94mDone\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Prefilter routine\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, N_POPULAR_ITEMS) # Prefilter routine\n",
    "\n",
    "data_val_lvl_1 = prefilter_items(data_val_lvl_1, N_POPULAR_ITEMS) # Prefilter routine\n",
    "data_train_lvl_2 = prefilter_items(data_val_lvl_1, N_POPULAR_ITEMS) # Prefilter routine\n",
    "data_val_lvl_2 = prefilter_items(data_val_lvl_1, N_POPULAR_ITEMS) # Prefilter routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get avg historical prices for all products\n",
    "itemid_to_price = get_price_list(data_train_lvl_1, data_val_lvl_1)\n",
    "user_bought_history = get_bought_ever_list(data_train_lvl_1, data_val_lvl_1)\n",
    "item_to_commodity =  get_item_commodities_list(item_features)\n",
    "\n",
    "# data.groupby('item_id')['sales_value'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953c04034138442483f591521b0c388f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b755df9efae4b29b481ecf305838a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 8.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recommender = MainRecommender(data_train_lvl_1, itemid_to_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = data_train_lvl_1['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: '\u001b[94m296\u001b[0m' not in dict, add...\n",
      "user_id: '\u001b[94m2404\u001b[0m' not in dict, add...\n",
      "user_id: '\u001b[94m1987\u001b[0m' not in dict, add...\n",
      "user_id: '\u001b[94m2259\u001b[0m' not in dict, add...\n"
     ]
    }
   ],
   "source": [
    "users_lvl_2 = pd.DataFrame(data_train_lvl_2['user_id'].unique())\n",
    "users_lvl_2.columns = ['user_id']\n",
    "users_lvl_2['candidates'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'item_id'\n",
    "\n",
    "users_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "users_lvl_2['drop'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = data_train_lvl_2[['user_id', 'item_id']].copy()\n",
    "targets_lvl_2['target'] = 1  # тут только покупки \n",
    "\n",
    "targets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_lvl_2['target'].fillna(0, inplace= True)\n",
    "targets_lvl_2.drop('drop', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Feats Preparation\"\"\"\n",
    "\n",
    "\n",
    "### USER FEATS\n",
    "\n",
    "combined_user_features = user_features.merge(data_train_lvl_2, on='user_id', how='left')\n",
    "\n",
    "# Income feature prepare\n",
    "income_desc_lst = list(user_features.income_desc.unique())\n",
    "income_desc_2_income = [int(re.search(r'\\d{2,3}', l)[0]) for l in income_desc_lst]\n",
    "income_dict = dict(zip(income_desc_lst, income_desc_2_income))\n",
    "\n",
    "user_features['income, x1000 $'] = user_features['income_desc'].replace(income_dict)\n",
    "user_features.drop('income_desc', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Age feature prepare\n",
    "age_desc_lst = list(user_features.age_desc.unique())\n",
    "age_desc_2_age = [int(re.search(r'\\d{2}', l)[0]) for l in age_desc_lst]\n",
    "age_dict = dict(zip(age_desc_lst, age_desc_2_age))\n",
    "\n",
    "user_features['age'] = user_features['age_desc'].replace(age_dict)\n",
    "user_features.drop('age_desc', axis=1, inplace=True)\n",
    "\n",
    "# Combined feats\n",
    "\n",
    "# Mean сheck\n",
    "user_check = combined_user_features.groupby(['user_id'])['sales_value'].sum().reset_index()\n",
    "user_check_cnt = combined_user_features.groupby('user_id')['basket_id'].count().reset_index()\n",
    "user_check_cnt.rename(columns={'basket_id': 'baskets_cnt'}, inplace=True)\n",
    "\n",
    "average_check = user_check.merge(user_check_cnt)\n",
    "\n",
    "average_check['avg_check'] = average_check['sales_value'] / average_check['baskets_cnt']\n",
    "average_check = average_check.drop(['sales_value', 'baskets_cnt'], axis=1)\n",
    "user_features = user_features.merge(average_check, how='left')\n",
    "\n",
    "\n",
    "### ITEM FEATS\n",
    "\n",
    "combined_item_features = item_features.merge(data_train_lvl_2, on='item_id', how='left')\n",
    "\n",
    "\n",
    "### Sold cound\n",
    "item_count = combined_item_features.groupby(['item_id'])['quantity'].count().reset_index()\n",
    "item_count.rename(columns={'quantity': 'sales_quantity'}, inplace=True)\n",
    "\n",
    "item_count['sales_quantity_p_week'] = item_count['sales_quantity'] / combined_item_features['week_no'].nunique()\n",
    "item_features = item_features.merge(item_count, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incomes dict: {'35-49K': 35, '50-74K': 50, '25-34K': 25, '75-99K': 75, 'Under 15K': 15, '100-124K': 100, '15-24K': 15, '125-149K': 125, '150-174K': 150, '250K+': 250, '175-199K': 175, '200-249K': 200}\n",
      "\n",
      "Ages dict: {'65+': 65, '45-54': 45, '25-34': 25, '35-44': 35, '19-24': 19, '55-64': 55}\n"
     ]
    }
   ],
   "source": [
    "print(f'Incomes dict: {income_dict}\\n')\n",
    "print(f'Ages dict: {age_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = targets_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "targets_lvl_2 = targets_lvl_2.merge(user_features, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08448979968955576"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_lvl_2['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = targets_lvl_2.drop('target', axis=1)\n",
    "y_train = targets_lvl_2[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manufacturer',\n",
       " 'department',\n",
       " 'brand',\n",
       " 'commodity_desc',\n",
       " 'sub_commodity_desc',\n",
       " 'curr_size_of_product',\n",
       " 'sub_commodity_desc_code',\n",
       " 'sales_quantity',\n",
       " 'sales_quantity_p_week',\n",
       " 'marital_status_code',\n",
       " 'homeowner_desc',\n",
       " 'hh_comp_desc',\n",
       " 'household_size_desc',\n",
       " 'kid_category_desc',\n",
       " 'income, x1000 $',\n",
       " 'age',\n",
       " 'avg_check']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats = X_train.columns[2:].tolist()\n",
    "X_train[cat_feats] = X_train[cat_feats].astype('category')\n",
    "\n",
    "cat_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:814: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt',\n",
       "               categorical_column=['manufacturer', 'department', 'brand',\n",
       "                                   'commodity_desc', 'sub_commodity_desc',\n",
       "                                   'curr_size_of_product',\n",
       "                                   'sub_commodity_desc_code', 'sales_quantity',\n",
       "                                   'sales_quantity_p_week',\n",
       "                                   'marital_status_code', 'homeowner_desc',\n",
       "                                   'hh_comp_desc', 'household_size_desc',\n",
       "                                   'kid_category_desc', 'income, x1000 $',\n",
       "                                   'age', 'avg_check'],\n",
       "               class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
       "               learning_rate=0.1, max_depth=5, min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "               n_jobs=-1, num_leaves=31, objective='binary', random_state=None,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgb = LGBMClassifier(objective='binary', max_depth=5, categorical_column=cat_feats)\n",
    "lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'item_id', 'manufacturer', 'department', 'brand',\n",
       "       'commodity_desc', 'sub_commodity_desc', 'curr_size_of_product',\n",
       "       'sub_commodity_desc_code', 'sales_quantity', 'sales_quantity_p_week',\n",
       "       'marital_status_code', 'homeowner_desc', 'hh_comp_desc',\n",
       "       'household_size_desc', 'kid_category_desc', 'income, x1000 $', 'age',\n",
       "       'avg_check'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0846277029028436\n"
     ]
    }
   ],
   "source": [
    "### Validation prep\n",
    "\n",
    "\n",
    "result_lvl_2 = data_val_lvl_2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_2.columns=['user_id', 'actual']\n",
    "\n",
    "\n",
    "val_users_lvl_2 = pd.DataFrame(data_val_lvl_2['user_id'].unique())\n",
    "val_users_lvl_2.columns = ['user_id']\n",
    "# Warm start\n",
    "# train_lvl_2_users = data_train_lvl_1['user_id'].unique()\n",
    "val_users_lvl_2 = val_users_lvl_2[val_users_lvl_2['user_id'].isin(train_users)]\n",
    "\n",
    "val_users_lvl_2['candidates'] = val_users_lvl_2['user_id'].apply(\n",
    "    lambda x: recommender.get_own_recommendations(x, N=200))\n",
    "\n",
    "\n",
    "\n",
    "s2 = val_users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s2.name = 'item_id'\n",
    "val_users_lvl_2 = val_users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "val_users_lvl_2['drop'] = 1 \n",
    "\n",
    "\n",
    "val_targets_lvl_2 = data_val_lvl_2[['user_id', 'item_id']].copy()\n",
    "val_targets_lvl_2['target'] = 1  # тут только покупки \n",
    "\n",
    "val_targets_lvl_2 = val_users_lvl_2.merge(val_targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "val_targets_lvl_2.dropna(0, subset=['item_id'],inplace=True)\n",
    "val_targets_lvl_2['item_id'] = val_targets_lvl_2['item_id'].astype('int64')\n",
    "\n",
    "\n",
    "val_targets_lvl_2['target'].fillna(0, inplace= True)\n",
    "val_targets_lvl_2.drop('drop', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "val_targets_lvl_2 = val_targets_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "val_targets_lvl_2 = val_targets_lvl_2.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "print(val_targets_lvl_2['target'].mean())\n",
    "\n",
    "X_val = val_targets_lvl_2.drop('target', axis=1)\n",
    "\n",
    "y_val = targets_lvl_2[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[cat_feats] = X_val[cat_feats].astype('category')\n",
    "\n",
    "val_preds = lgb.predict_proba(X_val)[:, 1]\n",
    "X_val['predict'] = val_preds\n",
    "X_val.sort_values(['user_id', 'predict'], ascending=False, inplace=True)\n",
    "result = X_val.groupby('user_id').head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = result.groupby('user_id')['item_id']\n",
    "recomendations = []\n",
    "for user, preds in recs:\n",
    "    recomendations.append({'user_id': user, 'recomendations': preds.tolist()})\n",
    "    \n",
    "recomendations = pd.DataFrame(recomendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot start correction\n",
    "\n",
    "result_lvl_2 = result_lvl_2.merge(recomendations, how='left')\n",
    "result_lvl_2.dropna(0, subset=['recomendations'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>recomendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[829323, 940947, 968164, 995242, 1082185, 1082...</td>\n",
       "      <td>[8293439, 8293439, 8293439, 8293439, 1106523, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[821083, 828106, 833025, 885023, 899624, 90332...</td>\n",
       "      <td>[957232, 1106523, 1106523, 1029743, 1082185, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[920626, 1053690, 13842214]</td>\n",
       "      <td>[13842214, 13945244, 1013928, 9526628, 1110244...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[831063, 883932, 891423, 908283, 962229, 10213...</td>\n",
       "      <td>[1106523, 1029743, 1029743, 1082185, 1126899, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[850102, 897088, 1062782, 1037863, 1119051, 12...</td>\n",
       "      <td>[1098844, 1015296, 1015296, 1119051, 1119051, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>2496</td>\n",
       "      <td>[824915, 899624, 900208, 907631, 916122, 92010...</td>\n",
       "      <td>[1065593, 832678, 5569230, 6534035, 965842, 90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>2497</td>\n",
       "      <td>[857503, 896613, 1024306, 870515, 897125, 9706...</td>\n",
       "      <td>[835243, 6533936, 854754, 12731436, 1081189, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>2498</td>\n",
       "      <td>[839243, 951197, 1070820, 1100379, 871337, 918...</td>\n",
       "      <td>[1070820, 1070820, 1085604, 901776, 901776, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>2499</td>\n",
       "      <td>[853354, 882308, 830887, 833458, 865992, 89962...</td>\n",
       "      <td>[1085604, 1070820, 1070820, 13842090, 13945244...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>2500</td>\n",
       "      <td>[999858, 1096317, 898349, 904574, 965766, 1019...</td>\n",
       "      <td>[1019643, 1048257, 859237, 978974, 6534030, 96...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2106 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                             actual  \\\n",
       "0           1  [829323, 940947, 968164, 995242, 1082185, 1082...   \n",
       "1           2  [821083, 828106, 833025, 885023, 899624, 90332...   \n",
       "2           3                        [920626, 1053690, 13842214]   \n",
       "3           4  [831063, 883932, 891423, 908283, 962229, 10213...   \n",
       "4           6  [850102, 897088, 1062782, 1037863, 1119051, 12...   \n",
       "...       ...                                                ...   \n",
       "2105     2496  [824915, 899624, 900208, 907631, 916122, 92010...   \n",
       "2106     2497  [857503, 896613, 1024306, 870515, 897125, 9706...   \n",
       "2107     2498  [839243, 951197, 1070820, 1100379, 871337, 918...   \n",
       "2108     2499  [853354, 882308, 830887, 833458, 865992, 89962...   \n",
       "2109     2500  [999858, 1096317, 898349, 904574, 965766, 1019...   \n",
       "\n",
       "                                         recomendations  \n",
       "0     [8293439, 8293439, 8293439, 8293439, 1106523, ...  \n",
       "1     [957232, 1106523, 1106523, 1029743, 1082185, 1...  \n",
       "2     [13842214, 13945244, 1013928, 9526628, 1110244...  \n",
       "3     [1106523, 1029743, 1029743, 1082185, 1126899, ...  \n",
       "4     [1098844, 1015296, 1015296, 1119051, 1119051, ...  \n",
       "...                                                 ...  \n",
       "2105  [1065593, 832678, 5569230, 6534035, 965842, 90...  \n",
       "2106  [835243, 6533936, 854754, 12731436, 1081189, 9...  \n",
       "2107  [1070820, 1070820, 1085604, 901776, 901776, 11...  \n",
       "2108  [1085604, 1070820, 1070820, 13842090, 13945244...  \n",
       "2109  [1019643, 1048257, 859237, 978974, 6534030, 96...  \n",
       "\n",
       "[2106 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter on 1000\n",
      "iter on 2000\n",
      "iter on 2500\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_lvl_2 = postfilter_items(result_lvl_2,\n",
    "                            recommender.overall_top_purchases,\n",
    "                            item_to_commodity,\n",
    "                            itemid_to_price,\n",
    "                            user_bought_history,\n",
    "                            n=N_FIN_RECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>recomendations</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[829323, 940947, 968164, 995242, 1082185, 1082...</td>\n",
       "      <td>[8293439, 8293439, 8293439, 8293439, 1106523, ...</td>\n",
       "      <td>[8293439, 981760, 5569230, 1126899, 874972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[821083, 828106, 833025, 885023, 899624, 90332...</td>\n",
       "      <td>[957232, 1106523, 1106523, 1029743, 1082185, 1...</td>\n",
       "      <td>[957232, 1106523, 981760, 5569230, 874972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[920626, 1053690, 13842214]</td>\n",
       "      <td>[13842214, 13945244, 1013928, 9526628, 1110244...</td>\n",
       "      <td>[13842214, 13945244, 1013928, 9526628, 1110244]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[831063, 883932, 891423, 908283, 962229, 10213...</td>\n",
       "      <td>[1106523, 1029743, 1029743, 1082185, 1126899, ...</td>\n",
       "      <td>[1106523, 981760, 5569230, 1082185, 874972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[850102, 897088, 1062782, 1037863, 1119051, 12...</td>\n",
       "      <td>[1098844, 1015296, 1015296, 1119051, 1119051, ...</td>\n",
       "      <td>[1098844, 1015296, 981760, 1119051, 874972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>2496</td>\n",
       "      <td>[824915, 899624, 900208, 907631, 916122, 92010...</td>\n",
       "      <td>[1065593, 832678, 5569230, 6534035, 965842, 90...</td>\n",
       "      <td>[1065593, 832678, 5569230, 981760, 874972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>2497</td>\n",
       "      <td>[857503, 896613, 1024306, 870515, 897125, 9706...</td>\n",
       "      <td>[835243, 6533936, 854754, 12731436, 1081189, 9...</td>\n",
       "      <td>[835243, 6533936, 854754, 12731436, 874972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>2498</td>\n",
       "      <td>[839243, 951197, 1070820, 1100379, 871337, 918...</td>\n",
       "      <td>[1070820, 1070820, 1085604, 901776, 901776, 11...</td>\n",
       "      <td>[1070820, 981760, 1085604, 901776, 874972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>2499</td>\n",
       "      <td>[853354, 882308, 830887, 833458, 865992, 89962...</td>\n",
       "      <td>[1085604, 1070820, 1070820, 13842090, 13945244...</td>\n",
       "      <td>[1085604, 1070820, 981760, 13842090, 874972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>2500</td>\n",
       "      <td>[999858, 1096317, 898349, 904574, 965766, 1019...</td>\n",
       "      <td>[1019643, 1048257, 859237, 978974, 6534030, 96...</td>\n",
       "      <td>[1019643, 1048257, 859237, 978974, 874972]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2106 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                             actual  \\\n",
       "0           1  [829323, 940947, 968164, 995242, 1082185, 1082...   \n",
       "1           2  [821083, 828106, 833025, 885023, 899624, 90332...   \n",
       "2           3                        [920626, 1053690, 13842214]   \n",
       "3           4  [831063, 883932, 891423, 908283, 962229, 10213...   \n",
       "4           6  [850102, 897088, 1062782, 1037863, 1119051, 12...   \n",
       "...       ...                                                ...   \n",
       "2105     2496  [824915, 899624, 900208, 907631, 916122, 92010...   \n",
       "2106     2497  [857503, 896613, 1024306, 870515, 897125, 9706...   \n",
       "2107     2498  [839243, 951197, 1070820, 1100379, 871337, 918...   \n",
       "2108     2499  [853354, 882308, 830887, 833458, 865992, 89962...   \n",
       "2109     2500  [999858, 1096317, 898349, 904574, 965766, 1019...   \n",
       "\n",
       "                                         recomendations  \\\n",
       "0     [8293439, 8293439, 8293439, 8293439, 1106523, ...   \n",
       "1     [957232, 1106523, 1106523, 1029743, 1082185, 1...   \n",
       "2     [13842214, 13945244, 1013928, 9526628, 1110244...   \n",
       "3     [1106523, 1029743, 1029743, 1082185, 1126899, ...   \n",
       "4     [1098844, 1015296, 1015296, 1119051, 1119051, ...   \n",
       "...                                                 ...   \n",
       "2105  [1065593, 832678, 5569230, 6534035, 965842, 90...   \n",
       "2106  [835243, 6533936, 854754, 12731436, 1081189, 9...   \n",
       "2107  [1070820, 1070820, 1085604, 901776, 901776, 11...   \n",
       "2108  [1085604, 1070820, 1070820, 13842090, 13945244...   \n",
       "2109  [1019643, 1048257, 859237, 978974, 6534030, 96...   \n",
       "\n",
       "                                               result  \n",
       "0         [8293439, 981760, 5569230, 1126899, 874972]  \n",
       "1          [957232, 1106523, 981760, 5569230, 874972]  \n",
       "2     [13842214, 13945244, 1013928, 9526628, 1110244]  \n",
       "3         [1106523, 981760, 5569230, 1082185, 874972]  \n",
       "4         [1098844, 1015296, 981760, 1119051, 874972]  \n",
       "...                                               ...  \n",
       "2105       [1065593, 832678, 5569230, 981760, 874972]  \n",
       "2106      [835243, 6533936, 854754, 12731436, 874972]  \n",
       "2107       [1070820, 981760, 1085604, 901776, 874972]  \n",
       "2108     [1085604, 1070820, 981760, 13842090, 874972]  \n",
       "2109       [1019643, 1048257, 859237, 978974, 874972]  \n",
       "\n",
       "[2106 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision compare\n",
    "\n",
    "# one_lvl_precision = result_lvl_1.apply(lambda row: precision_at_k(row['als_rec'], row['actual'], k=200), axis=1).mean()\n",
    "\n",
    "res = result_lvl_2.apply(\n",
    "    lambda row: money_precision_at_k(row['result'], row['actual'], itemid_to_price, k=5), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14146137433787775"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
