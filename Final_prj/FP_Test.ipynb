{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Layered Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для src, utils, metrics вы можете скачать из [этого](https://github.com/geangohn/recsys-tutorial) github репозитория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "### TODO REMOVE CONSTRAINTS:\n",
    "#############################\n",
    "\n",
    "\"\"\"\n",
    "- Для каждого юзера 5 рекомендаций (иногда модели могут возвращать < 5)\n",
    "- 2 новых товара (юзер никогда не покупал)\n",
    "- 1 дорогой товар, > 7 долларов\n",
    "- Все товары из разных категорий (категория - sub_commodity_desc)\n",
    "\n",
    "- Стоимость каждого рекомендованного товара > 1 доллара\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import re\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "import os, sys\n",
    "\n",
    "# from src.metrics import money_precision_at_k\n",
    "from implicit.nearest_neighbours import ItemItemRecommender, bm25_weight \n",
    "# from src.utils import prefilter_items\n",
    "# from src.recommenders import MainRecommender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Settings && Constants \n",
    "###############################\n",
    "\n",
    "DATA_PATH = './data/retail_train.csv'\n",
    "TEST_PATH = './data/retail_test1.csv'\n",
    "ITEM_FEATURES_PATH = './data/product.csv'\n",
    "USER_FEATURES_PATH = './data/hh_demographic.csv'\n",
    "\n",
    "TEST_SIZE_WEEKS = (6,3)\n",
    "N_POPULAR_ITEMS = 5000\n",
    "INIT_NUM_RECS = 300\n",
    "N_FIN_RECS = 5\n",
    "# NUM_THREADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# MODULES \n",
    "###############################\n",
    "\n",
    "value_string_template = '\\033[91m[[value]]\\033[0m'\n",
    "\n",
    "def prefilter_items(data, take_n_popular=5000, margin_slice_rate=0.9):\n",
    "    \n",
    "    \"\"\"Предфильтрация товаров\"\"\"\n",
    "    \n",
    "    n_before = value_string_template.replace('[[value]]', str(data['item_id'].nunique()))\n",
    "    \n",
    "    \n",
    "    # drop 0 purchases\n",
    "    data = data.drop(data[data['quantity']==0].index)\n",
    "    \n",
    "    # расчет цены единицы товара\n",
    "    data['price'] = data['sales_value'] / data['quantity']\n",
    "    \n",
    "    # 1. Удаление товаров, со средней ценой < 1$\n",
    "    data = data[data['price'] > 1]\n",
    "    \n",
    "    # 2. Удаление товаров со средней ценой > 30$\n",
    "    data = data[data['price'] < 30]\n",
    "    \n",
    "    # 3. Удаление 10% товаров c наименьшей выручкой (сдвигает минимум выручки с 1.1$ до 94.8$ для unsplitted data)\n",
    "    marginality = data.groupby('item_id')['sales_value'].sum().reset_index()\n",
    "    ten_percent_slice_idx = int(marginality.shape[0] * margin_slice_rate)\n",
    "\n",
    "    top_margin = marginality.sort_values('sales_value', ascending=False)[:ten_percent_slice_idx].item_id.tolist()\n",
    "    data = data[data['item_id'].isin(top_margin)]\n",
    "    \n",
    "    # 4. Выбор топ-N самых популярных товаров (N = take_n_popular)\n",
    "    popularity = data.groupby('item_id')['quantity'].sum().reset_index()\n",
    "    top_popular = popularity.sort_values('quantity', ascending=False)[:take_n_popular].item_id.tolist()\n",
    "    data = data[data['item_id'].isin(top_popular)]\n",
    "    \n",
    "    n_after = value_string_template.replace('[[value]]', str(data['item_id'].nunique()))\n",
    "    print(f\"Items variety reduced from: {n_before} to: {n_after} samples...\", end='')\n",
    "    print('\\033[94mDone\\033[0m')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_raw_data_splits(data_path, n_weeks_split=(6, 4), mode=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return data splits depending on mode:\n",
    "    \n",
    "    MODE 0: No split\n",
    "    MODE 1: One level split\n",
    "    MODE 2: Two level split\n",
    "    \n",
    "    data_train: base train split\n",
    "    data_test: used for lvl 1 validation & lvl 2 train\n",
    "    data_val: used for lvl 2 validation\n",
    "    \n",
    "    for lvl_size_weeks in [6, 3] returns:   \n",
    "    train_lvl1: week_no (1-85), val_lvl1 & train_lvl2: week_no (86-91), val_lvl2: week_no (92-95)\n",
    "    \"\"\"\n",
    "    print(\"Preparing raw data...\", end='')\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    if mode == 0:\n",
    "        return data\n",
    "    \n",
    "    if mode == 1:\n",
    "        print(\"Selected one level mode...\", end='')\n",
    "        data_train = data[data['week_no'] < data['week_no'].max() - (n_weeks_split[0] + n_weeks_split[1])]\n",
    "        data_test = data[(data['week_no'] >= data['week_no'].max() - (n_weeks_split[0] + n_weeks_split[1]))]\n",
    "        print('\\033[94mDone\\033[0m') \n",
    "        \n",
    "        return data, data_train, data_test\n",
    "    \n",
    "    elif mode == 2:\n",
    "        print(\"Selected two level mode...\", end='')\n",
    "        data_train = data[data['week_no'] < data['week_no'].max() - (n_weeks_split[0] + n_weeks_split[1])]\n",
    "        data_test = data[(data['week_no'] >= data['week_no'].max() /\n",
    "                               - (n_weeks_split[0] + n_weeks_split[1])) &\n",
    "                              (data['week_no'] < data['week_no'].max() - (n_weeks_split[1]))]\n",
    "        data_val_1 = data_test.copy()\n",
    "        data_val_2 = data[data['week_no'] >= data['week_no'].max() - n_weeks_split[1]] \n",
    "        print('\\033[94mDone\\033[0m') \n",
    "\n",
    "        return data, data_train, data_test, data_val_1, data_val_2\n",
    "    else:\n",
    "        print('\\033[91mError. Mode not understood\\033[0m')\n",
    "        return None\n",
    "\n",
    "    \n",
    "def get_price_list(data_1, data_2, _id='item_id', target='price'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Used 4 creating check dict (price list)\n",
    "    From all historical data\n",
    "    Can be used once and stored then updated if needs\n",
    "    \"\"\"\n",
    "    \n",
    "    pl_1 = data_1.groupby(_id)[target].mean().reset_index()\n",
    "    pl_2 = data_2.groupby(_id)[target].mean().reset_index()\n",
    "    d1 = dict(zip(pl_1[_id], pl_1[target]))\n",
    "    d2 = dict(zip(pl_2[_id], pl_2[target]))\n",
    "    pl_emb = {**d1, **d2}\n",
    "    \n",
    "    return pl_emb\n",
    "\n",
    "\n",
    "def get_bought_ever_list(data_1, data_2, _id='user_id', target='item_id'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Used 4 creating check dict (user's ever bought list)\n",
    "    From all historical data\n",
    "    Can be used once and stored then updated if needs\n",
    "    \"\"\"\n",
    "    \n",
    "    pl_1 = data_1.groupby(_id)[target].unique().reset_index()\n",
    "    pl_2 = data_2.groupby(_id)[target].unique().reset_index()\n",
    "    d1 = dict(zip(pl_1[_id], pl_1[target]))\n",
    "    d2 = dict(zip(pl_2[_id], pl_2[target]))\n",
    "    pl_emb = {**d1, **d2}\n",
    "    \n",
    "    return pl_emb\n",
    "\n",
    "\n",
    "def get_item_commodities_list(feats, _id='item_id', target='sub_commodity_desc_code'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Used 4 creating check dict (item_id - commodity_type)\n",
    "    From all historical data\n",
    "    Can be used once and stored then updated if needs\n",
    "    \"\"\"\n",
    "    \n",
    "    res = dict(zip(feats[_id], feats[target]))\n",
    "    return res\n",
    "        \n",
    "    \n",
    "def preprare_features(item_features_path, user_features_path):\n",
    "    \n",
    "    \"\"\"Loads raw item and user features:\"\"\"\n",
    "    \n",
    "    print(\"Preparing raw features...\", end='')\n",
    "    item_features = pd.read_csv(item_features_path)\n",
    "    user_features = pd.read_csv(user_features_path)\n",
    "\n",
    "    # column processing\n",
    "    item_features.columns = [col.lower() for col in item_features.columns]\n",
    "    user_features.columns = [col.lower() for col in user_features.columns]\n",
    "    item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "    user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "    \n",
    "    # encode commodities in item_features\n",
    "    item_features['sub_commodity_desc'] = pd.Categorical(item_features['sub_commodity_desc'])\n",
    "    item_features['sub_commodity_desc_code'] = item_features['sub_commodity_desc'].cat.codes\n",
    "    \n",
    "    print('\\033[94mDone\\033[0m')\n",
    "    \n",
    "    return item_features, user_features\n",
    "\n",
    "\n",
    "\n",
    "class MainRecommender:\n",
    "    \"\"\"Рекоммендации, которые можно получить из ALS\n",
    "    Input\n",
    "    -----\n",
    "    user_item_matrix: pd.DataFrame\n",
    "        Матрица взаимодействий user-item\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, prices, weighting=True):\n",
    "\n",
    "        # Топ покупок каждого юзера\n",
    "        self.top_purchases = data.groupby(['user_id', 'item_id'])['quantity'].count().reset_index()\n",
    "        self.top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
    "\n",
    "        # Топ покупок по всему датасету\n",
    "        self.overall_top_purchases = data.groupby('item_id')['quantity'].count().reset_index()\n",
    "        self.overall_top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
    "        self.overall_top_purchases = self.overall_top_purchases.item_id.tolist()\n",
    "\n",
    "        self.user_item_matrix, self.matrix_index, self.matrix_columns = self._prepare_matrix(data)  # pd.DataFrame\n",
    "        self.id_to_itemid, self.id_to_userid, \\\n",
    "            self.itemid_to_id, self.userid_to_id = self._prepare_dicts(self.user_item_matrix)\n",
    "\n",
    "        if weighting:\n",
    "            self.user_item_matrix = bm25_weight(self.user_item_matrix.T).T\n",
    "\n",
    "        self.model = self.fit(self.user_item_matrix)\n",
    "        self.own_recommender = self.fit_own_recommender(self.user_item_matrix)\n",
    "        \n",
    "        self.item_factors = self.model.item_factors\n",
    "        self.user_factors = self.model.user_factors\n",
    "        self.price_list = prices\n",
    "        \n",
    "        self.items_emb_df, self.users_emb_df = self.get_embeddings(self)\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def get_embeddings(self):\n",
    "        items_emb = self.item_factors\n",
    "        items_emb_df = pd.DataFrame(items_emb)\n",
    "        items_emb_df.reset_index(inplace=True)\n",
    "        items_emb_df['item_id'] = items_emb_df['index'].apply(lambda x: self.id_to_itemid[x])\n",
    "        items_emb_df = items_emb_df.drop('index', axis=1)\n",
    "\n",
    "        users_emb = self.user_factors\n",
    "        users_emb_df = pd.DataFrame(users_emb)\n",
    "        users_emb_df.reset_index(inplace=True)\n",
    "        users_emb_df['user_id'] = users_emb_df['index'].apply(lambda x: self.id_to_userid[x])\n",
    "        users_emb_df = users_emb_df.drop('index', axis=1)\n",
    "\n",
    "        return items_emb_df, users_emb_df\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_matrix(data):\n",
    "        \"\"\"Готовит user-item матрицу\"\"\"\n",
    "        user_item_matrix = pd.pivot_table(data,\n",
    "                                          index='user_id', \n",
    "                                          columns='item_id',\n",
    "                                          values='quantity',\n",
    "                                          aggfunc='count',\n",
    "                                          fill_value=0\n",
    "                                          )\n",
    "        matrix_index = user_item_matrix.index\n",
    "        matrix_columns = user_item_matrix.columns\n",
    "\n",
    "        user_item_matrix = user_item_matrix.astype(float)  # необходимый тип матрицы для implicit\n",
    "        return user_item_matrix, matrix_index, matrix_columns\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_dicts(user_item_matrix):\n",
    "        \"\"\"Подготавливает вспомогательные словари\"\"\"\n",
    "\n",
    "        userids = user_item_matrix.index.values\n",
    "        itemids = user_item_matrix.columns.values\n",
    "\n",
    "        matrix_userids = np.arange(len(userids))\n",
    "        matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "        id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "        id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "        itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "        userid_to_id = dict(zip(userids, matrix_userids))\n",
    "\n",
    "        return id_to_itemid, id_to_userid, itemid_to_id, userid_to_id\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def fit_own_recommender(user_item_matrix):\n",
    "        \n",
    "        \"\"\"Обучает модель, которая рекомендует товары, среди товаров, купленных юзером\"\"\"\n",
    "        \n",
    "        own_recommender = ItemItemRecommender(K=1)\n",
    "        own_recommender.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "        return own_recommender\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def fit(user_item_matrix, n_factors=32, regularization=0.001, iterations=20, num_threads=8):\n",
    "        \n",
    "        \"\"\"Обучает ALS\"\"\"\n",
    "        \n",
    "        model = AlternatingLeastSquares(factors=n_factors,\n",
    "                                        regularization=regularization,\n",
    "                                        iterations=iterations,\n",
    "                                        num_threads=num_threads)\n",
    "        model.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def _update_dict(self, user_id):\n",
    "        \n",
    "        \"\"\"Если появился новый user / item, то нужно обновить словари\"\"\"\n",
    "        \n",
    "        if user_id not in self.userid_to_id.keys():\n",
    "            print(f\"user_id: '\\033[94m{user_id}\\033[0m' not in dict, add...\")\n",
    "            max_id = max(list(self.userid_to_id.values()))\n",
    "            max_id += 1\n",
    "            self.userid_to_id.update({user_id: max_id})\n",
    "            self.id_to_userid.update({max_id: user_id})\n",
    "            \n",
    "\n",
    "    def _get_similar_item(self, item_id):\n",
    "        \n",
    "        \"\"\"Находит товар, похожий на item_id\"\"\"\n",
    "        \n",
    "        # Товар похож на себя -> рекомендуем 2 товара\n",
    "        recs = self.model.similar_items(self.itemid_to_id[item_id], N=2)\n",
    "        top_rec = recs[1][0]  # И берем второй (не товар из аргумента метода)\n",
    "        return self.id_to_itemid[top_rec]\n",
    "    \n",
    "\n",
    "    def _extend_with_top_popular(self, recommendations, N=5):\n",
    "        \n",
    "        \"\"\"Если кол-во рекоммендаций < N, то дополняем их топ-популярными\"\"\"\n",
    "        \n",
    "        if len(recommendations) < N:\n",
    "            recommendations.extend(self.overall_top_purchases[:N])\n",
    "            recommendations = recommendations[:N]\n",
    "        return recommendations\n",
    "    \n",
    "\n",
    "    def _get_recommendations(self, user, model, N=5):\n",
    "        \n",
    "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
    "        \n",
    "        \n",
    "        if user not in self.userid_to_id.keys():\n",
    "            self._update_dict(user_id=user)\n",
    "            res = []\n",
    "            res = self._extend_with_top_popular(res, N=N)\n",
    "        else:\n",
    "        \n",
    "        \n",
    "            res = [self.id_to_itemid[rec[0]] for rec in model.recommend(userid=self.userid_to_id[user],\n",
    "                                            user_items=csr_matrix(self.user_item_matrix).tocsr(),\n",
    "                                            N=N,\n",
    "                                            filter_already_liked_items=False,\n",
    "                                            filter_items=None,\n",
    "                                            recalculate_user=True)]\n",
    "            res = self._extend_with_top_popular(res, N=N)\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "    \n",
    "\n",
    "    def get_als_recommendations(self, user, N=5):\n",
    "        \n",
    "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
    "        \n",
    "#         self._update_dict(user_id=user)\n",
    "        return self._get_recommendations(user, model=self.model, N=N)\n",
    "    \n",
    "\n",
    "    def get_own_recommendations(self, user, N=5):\n",
    "        \n",
    "        \"\"\"Рекомендуем товары среди тех, которые юзер уже купил\"\"\"\n",
    "        \n",
    "#         self._update_dict(user_id=user)\n",
    "        return self._get_recommendations(user, model=self.own_recommender, N=N)\n",
    "    \n",
    "\n",
    "    def get_similar_items_recommendation(self, user, N=5):\n",
    "        \n",
    "        \"\"\"Рекомендуем товары, похожие на топ-N купленных юзером товаров\"\"\"\n",
    "        \n",
    "        top_users_purchases = self.top_purchases[self.top_purchases['user_id'] == user].head(N)\n",
    "\n",
    "        res = top_users_purchases['item_id'].apply(lambda x: self._get_similar_item(x)).tolist()\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "    \n",
    "\n",
    "    def get_similar_users_recommendation(self, user, N=5):\n",
    "        \n",
    "        \"\"\"Рекомендуем топ-N товаров, среди купленных похожими юзерами\"\"\"\n",
    "        \n",
    "        res = []\n",
    "\n",
    "        # Находим топ-N похожих пользователей\n",
    "        similar_users = self.model.similar_users(self.userid_to_id[user], N=N+1)\n",
    "        similar_users = [rec[0] for rec in similar_users]\n",
    "        similar_users = similar_users[1:]   # удалим юзера из запроса\n",
    "\n",
    "        for user in similar_users:\n",
    "            res.extend(self.get_own_recommendations(user, N=1))\n",
    "\n",
    "\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing raw data...Preparing raw data...Preparing raw features...\u001b[94mDone\u001b[0m\n",
      "Wall time: 4.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_train_lvl_1 = get_raw_data_splits(DATA_PATH, mode=0)\n",
    "data_val_lvl_1 = get_raw_data_splits(TEST_PATH, mode=0)\n",
    "\n",
    "# TWO LVL PREPARATION\n",
    "\n",
    "# data, data_train_lvl_1, data_val_lvl_1, data_train_lvl_2, data_val_lvl_2 = get_raw_data_splits(\n",
    "#     DATA_PATH, TEST_SIZE_WEEKS, mode=1)\n",
    "\n",
    "item_features, user_features = preprare_features(ITEM_FEATURES_PATH, USER_FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items variety reduced from: \u001b[91m89051\u001b[0m to: \u001b[91m5000\u001b[0m samples...\u001b[94mDone\u001b[0m\n",
      "Items variety reduced from: \u001b[91m20497\u001b[0m to: \u001b[91m5000\u001b[0m samples...\u001b[94mDone\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Prefilter routine\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, N_POPULAR_ITEMS) # Prefilter routine\n",
    "\n",
    "data_val_lvl_1 = prefilter_items(data_val_lvl_1, N_POPULAR_ITEMS) # Prefilter routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get avg historical prices for all products\n",
    "itemid_to_price = get_price_list(data_train_lvl_1, data_val_lvl_1)\n",
    "user_bought_history = get_bought_ever_list(data_train_lvl_1, data_val_lvl_1)\n",
    "item_to_commodity =  get_item_commodities_list(item_features)\n",
    "\n",
    "# data.groupby('item_id')['sales_value'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a59daf67d54c1eb8f4361b3952abbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6497dd9d6f04255aadc88b0102ab8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 9.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recommender = MainRecommender(data_train_lvl_1, itemid_to_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: '\u001b[94m1043\u001b[0m' not in dict, add...\n",
      "user_id: '\u001b[94m2325\u001b[0m' not in dict, add...\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result_lvl_1 = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_1.columns=['user_id', 'actual']\n",
    "result_lvl_1['base_rec'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_als_recommendations(x, N=INIT_NUM_RECS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid_items(res,\n",
    "                      user,\n",
    "                      item_to_commodity,\n",
    "                      itemid_to_price,\n",
    "                      user_bought_history,\n",
    "                      n=5,\n",
    "                      max_price_constraint=7,\n",
    "                      max_n_new_items_constraint=2\n",
    "                     ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Constraints Checker Module.\n",
    "    Check commended items for user.\n",
    "    Input: res:array with len=n\n",
    "    Return: error flag, one-hot encodded errors\n",
    "    \"\"\"\n",
    "    \n",
    "    # res: list result of n=5 elements\n",
    "    \n",
    "    err_flag = 0  # error flag\n",
    "    err_pos = np.zeros(len(res))  # penalty weights for items to change positions\n",
    "    user_history = user_bought_history[user][:10]  # user purchases of unique items history\n",
    "    price_checklist = np.zeros(len(res))  # price list for checking conditions\n",
    "    unique_checklist = np.zeros(len(res))  # unique item positions counter\n",
    "    \n",
    "    c = []\n",
    "    for i, item in enumerate(res):\n",
    "        commodity = item_to_commodity[item]\n",
    "        price_checklist[i] = itemid_to_price[item]        \n",
    "        \n",
    "        # check if code already exists in recs. If true change first duplicate\n",
    "        if commodity in c:\n",
    "            err_flag = 1\n",
    "            err_pos[i] += 1  # add penalty for mismatch element position\n",
    "            \n",
    "        # keep track of unique items\n",
    "        if item not in user_history:\n",
    "            unique_checklist[i] = 1\n",
    "        c.append(commodity)\n",
    "        \n",
    "    max_price = price_checklist[np.argmax(price_checklist)]\n",
    "    \n",
    "    # if no expensive items in list, mark last element\n",
    "    if max_price < max_price_constraint:\n",
    "        err_flag = 1\n",
    "        \n",
    "        # add penalty to last highest element\n",
    "        #  len(res-1) - np.argmax(err_pos[::-1]) keeps track on the last element if equal weights exist like 0\n",
    "        #  used in case of ranked elements\n",
    "        err_pos[len(res)-1 - np.argmax(err_pos[::-1])] += 1\n",
    "    \n",
    "    # if not enough unique elements, mark last element\n",
    "    if unique_checklist.sum() < max_n_new_items_constraint:\n",
    "        err_flag = 1\n",
    "        # add penalty to last highest element\n",
    "        err_pos[len(res)-1 - np.argmax(err_pos[::-1])] += 1\n",
    "#         np.where(err_pos==0)[0][-1]\n",
    "    \n",
    "    return err_flag, err_pos\n",
    "\n",
    "            \n",
    "\n",
    "def postfilter_items(data,\n",
    "                     pop_recs,\n",
    "                     item_to_commodity,\n",
    "                     itemid_to_price,\n",
    "                     user_bought_history,\n",
    "                     n=5,\n",
    "                     target_col='base_rec',\n",
    "                     res_col='result'\n",
    "                    ):    \n",
    "    \n",
    "    \"\"\"\n",
    "    Input: user recommendations: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # make result placeholders\n",
    "    data[res_col] = np.nan\n",
    "    data[res_col] = data[res_col].astype('object')\n",
    "    \n",
    "    \n",
    "    for index, row in data.iterrows():       \n",
    "        if row.user_id %500==0:\n",
    "            print(f\"iter on {row.user_id}\")\n",
    "        \n",
    "        recs = row[target_col]\n",
    "        result = recs[:n] # list with n item_id recs\n",
    "        flag, err_positions = check_valid_items(result,\n",
    "                                                row.user_id,\n",
    "                                                item_to_commodity,\n",
    "                                                itemid_to_price,\n",
    "                                                user_bought_history,\n",
    "                                                n)\n",
    "\n",
    "        take_from_pos = n + 1  # set initial position of new element to substitute as next # after existing recs\n",
    "        ov=0\n",
    "        while flag:\n",
    "            \n",
    "            pos_list = np.where(err_positions>0)[0]  # invalid element positions pointer\n",
    "            # change each invalid element \n",
    "            for pos in pos_list:\n",
    "                if take_from_pos%INIT_NUM_RECS==0 and not ov:  # INIT_NUM_RECS\n",
    "#                     print(take_from_pos)\n",
    "                    take_from_pos = 1\n",
    "                    ov=1\n",
    "                    \n",
    "                if ov:\n",
    "                    result[pos] = pop_recs[take_from_pos]\n",
    "                    take_from_pos +=1\n",
    "                    \n",
    "                else:\n",
    "                    result[pos] = recs[take_from_pos]\n",
    "                    take_from_pos +=1\n",
    "                \n",
    "            # check new recommendations\n",
    "            flag, err_positions = check_valid_items(result,\n",
    "                                                row.user_id,\n",
    "                                                item_to_commodity,\n",
    "                                                itemid_to_price,\n",
    "                                                user_bought_history,\n",
    "                                                n)        \n",
    "                    \n",
    "        data.at[index, res_col] = result\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter on 1000\n",
      "iter on 1500\n",
      "iter on 2500\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_lvl_1 = postfilter_items(result_lvl_1,\n",
    "                            recommender.overall_top_purchases,\n",
    "                            item_to_commodity,\n",
    "                            itemid_to_price,\n",
    "                            user_bought_history,\n",
    "                            n=N_FIN_RECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>base_rec</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[883616, 931136, 940947, 958046, 962568, 96576...</td>\n",
       "      <td>[1076954, 920200, 1094924, 1082212, 885290, 12...</td>\n",
       "      <td>[1076954, 920200, 1094924, 1082212, 909497]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[820291, 826784, 866211, 870608, 879769, 88502...</td>\n",
       "      <td>[977497, 1004906, 5569230, 1020581, 10456568, ...</td>\n",
       "      <td>[977497, 1004906, 5569230, 1020581, 874972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[827683, 908531, 989069, 1096727, 1130858, 113...</td>\n",
       "      <td>[951590, 1092026, 1122568, 937791, 944139, 101...</td>\n",
       "      <td>[951590, 1092026, 1122568, 937791, 1137346]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[956902, 960791, 1037863, 1119051, 840361, 847...</td>\n",
       "      <td>[1082185, 878996, 1042616, 863632, 1051516, 10...</td>\n",
       "      <td>[1082185, 878996, 1042616, 1037337, 8090440]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[855557, 930918, 954673, 957013, 963502, 99383...</td>\n",
       "      <td>[835285, 1060363, 856335, 1031833, 1003188, 87...</td>\n",
       "      <td>[835285, 1135932, 856335, 1031833, 854405]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>2494</td>\n",
       "      <td>[880427, 912137, 1039126, 1043301, 1060005, 11...</td>\n",
       "      <td>[1083446, 1081262, 995628, 5569471, 1120559, 8...</td>\n",
       "      <td>[1083446, 1081262, 1024032, 5569471, 1110111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>2496</td>\n",
       "      <td>[829291, 912704, 933067, 933835, 955370, 97970...</td>\n",
       "      <td>[844179, 1004906, 899624, 12810393, 916122, 10...</td>\n",
       "      <td>[844179, 1004906, 8065410, 12810393, 874972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>2498</td>\n",
       "      <td>[12386123, 920109, 1004945, 1030455]</td>\n",
       "      <td>[995242, 882496, 5565356, 873056, 882308, 9487...</td>\n",
       "      <td>[995242, 882496, 5565356, 873056, 882308]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>2499</td>\n",
       "      <td>[820321, 829291, 833458, 866528, 878996, 88015...</td>\n",
       "      <td>[859075, 1029743, 5568378, 5569327, 951590, 11...</td>\n",
       "      <td>[859075, 1029743, 5568378, 885697, 850102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>2500</td>\n",
       "      <td>[828143, 938622, 995242, 1011046, 1058997, 108...</td>\n",
       "      <td>[855356, 7168759, 7168890, 1069296, 1014458, 9...</td>\n",
       "      <td>[855356, 7168759, 12428436, 1069296, 970866]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1814 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                             actual  \\\n",
       "0           1  [883616, 931136, 940947, 958046, 962568, 96576...   \n",
       "1           2  [820291, 826784, 866211, 870608, 879769, 88502...   \n",
       "2           3  [827683, 908531, 989069, 1096727, 1130858, 113...   \n",
       "3           6  [956902, 960791, 1037863, 1119051, 840361, 847...   \n",
       "4           7  [855557, 930918, 954673, 957013, 963502, 99383...   \n",
       "...       ...                                                ...   \n",
       "1809     2494  [880427, 912137, 1039126, 1043301, 1060005, 11...   \n",
       "1810     2496  [829291, 912704, 933067, 933835, 955370, 97970...   \n",
       "1811     2498               [12386123, 920109, 1004945, 1030455]   \n",
       "1812     2499  [820321, 829291, 833458, 866528, 878996, 88015...   \n",
       "1813     2500  [828143, 938622, 995242, 1011046, 1058997, 108...   \n",
       "\n",
       "                                               base_rec  \\\n",
       "0     [1076954, 920200, 1094924, 1082212, 885290, 12...   \n",
       "1     [977497, 1004906, 5569230, 1020581, 10456568, ...   \n",
       "2     [951590, 1092026, 1122568, 937791, 944139, 101...   \n",
       "3     [1082185, 878996, 1042616, 863632, 1051516, 10...   \n",
       "4     [835285, 1060363, 856335, 1031833, 1003188, 87...   \n",
       "...                                                 ...   \n",
       "1809  [1083446, 1081262, 995628, 5569471, 1120559, 8...   \n",
       "1810  [844179, 1004906, 899624, 12810393, 916122, 10...   \n",
       "1811  [995242, 882496, 5565356, 873056, 882308, 9487...   \n",
       "1812  [859075, 1029743, 5568378, 5569327, 951590, 11...   \n",
       "1813  [855356, 7168759, 7168890, 1069296, 1014458, 9...   \n",
       "\n",
       "                                             result  \n",
       "0       [1076954, 920200, 1094924, 1082212, 909497]  \n",
       "1       [977497, 1004906, 5569230, 1020581, 874972]  \n",
       "2       [951590, 1092026, 1122568, 937791, 1137346]  \n",
       "3      [1082185, 878996, 1042616, 1037337, 8090440]  \n",
       "4        [835285, 1135932, 856335, 1031833, 854405]  \n",
       "...                                             ...  \n",
       "1809  [1083446, 1081262, 1024032, 5569471, 1110111]  \n",
       "1810   [844179, 1004906, 8065410, 12810393, 874972]  \n",
       "1811      [995242, 882496, 5565356, 873056, 882308]  \n",
       "1812     [859075, 1029743, 5568378, 885697, 850102]  \n",
       "1813   [855356, 7168759, 12428436, 1069296, 970866]  \n",
       "\n",
       "[1814 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def money_precision_at_k(recommended_list, bought_list, prices, k=5):\n",
    "    \n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list[:k])\n",
    "    \n",
    "    prices_recommended = np.array([prices[i] for i in recommended_list])\n",
    "    prices_bought = np.array([prices[i] for i in bought_list])\n",
    "    \n",
    "    flags = np.isin(bought_list, recommended_list)\n",
    "    precision = np.dot(flags, prices_bought) / np.dot(np.ones(k), prices_recommended)\n",
    "    \n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# money_precision_at_k(result_lvl_1['als_rec'][0], result_lvl_1['actual'][0], itemid_to_price, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = result_lvl_1.apply(lambda row: money_precision_at_k(row['result'], row['actual'], itemid_to_price, k=5), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07639438280692792"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "- Train 1 lvl split. No features, ignore new, ignore restrictions (week_no 1, 85, 91). Result metric: 0.6\n",
    "- Train 1 lvl split. No features, ignore new, ignore restrictions (week_no 1, 85, 95). Result metric: 0.19\n",
    "- =same=... recs for new users by popular items. Result metric: 0.177\n",
    "- Public-test validation, pop-recs filling, ignore restrictions. Result metric: 0.1\n",
    "- =same=... Follow restrictions (replace from als rec list, then popular). Result metric: 0.07\n",
    "- =same=... Follow restrictions (replace from popular rec list, then popular). Result metric: 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
